{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8159cabd-100f-4427-8529-a859c288b103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from custom_dataset import CustomDataset\n",
    "from collate import collate_fn\n",
    "from torch import nn\n",
    "import pickle\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4cb856-9b7f-49a4-9ccc-f33e12dea544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be4059f5-6533-49ca-94dc-5340dd4f1cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84949da5-f671-44a4-a2df-ef0e4d791b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pkl(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_list = pickle.load(file)\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402fc5b3-d569-4a13-82e3-9fe92619d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_wav = get_pkl('np_wavs_cut.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4053f9db-7a63-4272-9491-14b0e5b9ed53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_wav = np_wav[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38d51cbb-60db-4476-ba91-696afcf5bc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del np_wav "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d09e58-acd5-4076-8537-70f8c2ed8c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_list = get_pkl('str_list_cut.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6444c7ba-e462-4bdc-a8e0-c8585a555b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list = str_list[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e66648f-8cca-41ab-8698-95e573c0fdee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "32730\n"
     ]
    }
   ],
   "source": [
    "print(len(np_wav))\n",
    "print(len(str_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aabc663a-ae5e-48e1-b3c1-a49146a34b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_len(np_wav):    \n",
    "    length = [len(x) for x in np_wav]\n",
    "    \n",
    "    combined_list = list(zip(length, np_wav))\n",
    "\n",
    "    # Sort the combined list based on the elements of the first list\n",
    "    sorted_list = sorted(combined_list, key=lambda x: x[0])\n",
    "\n",
    "    # Separate the sorted elements into separate lists\n",
    "    sorted_first_list, sorted_second_list = zip(*sorted_list)\n",
    "    \n",
    "    return sorted_first_list, sorted_second_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4361aac2-95f3-4690-bb63-cc5955e70553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = max_len(np_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cff06178-5127-4f24-a8a9-c76f8edb989b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 937)\n",
      "(20, 937)\n",
      "(20, 937)\n",
      "(20, 937)\n",
      "(20, 937)\n",
      "(20, 937)\n",
      "(20, 938)\n",
      "(20, 938)\n",
      "(20, 938)\n",
      "(20, 938)\n"
     ]
    }
   ],
   "source": [
    "for i in y[-10:]:\n",
    "    mfcc = librosa.feature.mfcc(y=i.astype(float), sr=24000, hop_length=512)\n",
    "    print(mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78d1b774-7d4e-4513-8415-651143f1f01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, t, processed_data = signal.stft(y[3000], 24000, nperseg=1024)\n",
    "\n",
    "# Create a new array filled with zeros of the desired shape\n",
    "new_array = np.pad(processed_data, ((0, 0), (0, 939 - processed_data.shape[1])), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533a0c18-a3ef-477a-a11c-2932eeaebe31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(np_wav, str_list)\n",
    "dataloader = DataLoader(dataset, batch_size=256, collate_fn=collate_fn, num_workers=0) # + num thread num_workers=6,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea585593-ccff-477d-9f3d-acbfc02a2492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe53555-31e5-4dc3-92a6-368c2b6b1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(layers.Layer):\n",
    "    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n",
    "        super().__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(num_vocab, num_hid)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        x = self.emb(x)\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b9def-1299-4657-9242-709a8406ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizeChar:\n",
    "    def __init__(self, max_len=50):\n",
    "        self.vocab = (\n",
    "            [\"-\", \"#\", \"<\", \">\"]\n",
    "            + [chr(i + 96) for i in range(1, 27)]\n",
    "            + [\" \", \".\", \",\", \"?\"]\n",
    "        )\n",
    "        self.max_len = max_len\n",
    "        self.char_to_idx = {}\n",
    "        for i, ch in enumerate(self.vocab):\n",
    "            self.char_to_idx[ch] = i\n",
    "\n",
    "    def __call__(self, text):\n",
    "        text = text.lower()\n",
    "        text = text[: self.max_len - 2]\n",
    "        text = \"<\" + text + \">\"\n",
    "        pad_len = self.max_len - len(text)\n",
    "        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n",
    "\n",
    "    def get_vocabulary(self):\n",
    "        return self.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc85ce5-0cea-44fc-8116-46aa9a892b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = (\n",
    "            [\"-\", \"#\", \"<\", \">\"]\n",
    "            + [chr(i + 96) for i in range(1, 27)]\n",
    "            + [\" \", \".\", \",\", \"?\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d60de6-3aaf-432a-9633-987769f1a577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '#', '<', '>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', '.', ',', '?']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84cf84-2893-4b96-a038-ae5acc8f2065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e979947-5e37-445d-aacb-d8e1849c1f39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([256, 20, 938])\n",
      "1\n",
      "torch.Size([256, 20, 938])\n",
      "2\n",
      "torch.Size([256, 20, 938])\n",
      "3\n",
      "torch.Size([256, 20, 938])\n",
      "4\n",
      "torch.Size([256, 20, 938])\n",
      "5\n",
      "torch.Size([256, 20, 938])\n",
      "6\n",
      "torch.Size([256, 20, 938])\n",
      "7\n",
      "torch.Size([256, 20, 938])\n",
      "8\n",
      "torch.Size([256, 20, 938])\n",
      "9\n",
      "torch.Size([256, 20, 938])\n",
      "10\n",
      "torch.Size([256, 20, 938])\n",
      "11\n",
      "torch.Size([256, 20, 938])\n",
      "12\n",
      "torch.Size([256, 20, 938])\n",
      "13\n",
      "torch.Size([256, 20, 938])\n",
      "14\n",
      "torch.Size([256, 20, 938])\n",
      "15\n",
      "torch.Size([256, 20, 938])\n",
      "16\n",
      "torch.Size([256, 20, 938])\n",
      "17\n",
      "torch.Size([256, 20, 938])\n",
      "18\n",
      "torch.Size([256, 20, 938])\n",
      "19\n",
      "torch.Size([256, 20, 938])\n",
      "20\n",
      "torch.Size([256, 20, 938])\n",
      "21\n",
      "torch.Size([256, 20, 938])\n",
      "22\n",
      "torch.Size([256, 20, 938])\n",
      "23\n",
      "torch.Size([256, 20, 938])\n",
      "24\n",
      "torch.Size([256, 20, 938])\n",
      "25\n",
      "torch.Size([256, 20, 938])\n",
      "26\n",
      "torch.Size([256, 20, 938])\n",
      "27\n",
      "torch.Size([256, 20, 938])\n",
      "28\n",
      "torch.Size([256, 20, 938])\n",
      "29\n",
      "torch.Size([256, 20, 938])\n",
      "30\n",
      "torch.Size([256, 20, 938])\n",
      "31\n",
      "torch.Size([256, 20, 938])\n",
      "32\n",
      "torch.Size([256, 20, 938])\n",
      "33\n",
      "torch.Size([256, 20, 938])\n",
      "34\n",
      "torch.Size([256, 20, 938])\n",
      "35\n",
      "torch.Size([256, 20, 938])\n",
      "36\n",
      "torch.Size([256, 20, 938])\n",
      "37\n",
      "torch.Size([256, 20, 938])\n",
      "38\n",
      "torch.Size([256, 20, 938])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\Speech-Recognition\\custom_dataset.py:12\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    print(i)\n",
    "    print(data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
